---
title: "Project 3: The Ames Housing Dataset"
author: "Sean Tsai, Olli Rissanen, Kit Tsang, Ying Jie Chin, Abhinav Alluri"
date: "4/17/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



# Table of Contents

#### 1. Description of the Data and our Project

#### 2. General Data Exploration

#### 3. Data Cleaning

#### 4. Linear and Stepwise Regressions

#### 5. Creating a Normalized Version of the Data

#### 6. Dividing Data into Train and Test Parts

#### 7. Individual Predictive Models

#### 8. Combined Prediction Models

#### 9. Conclusion



# 1. Description of the Data and our Project

The Ames Housing Dataset is an incredible dataset with 79 explanatory variables describing almost every aspect of residential homes in Ames, Iowa, a city that serves as a home for the Iowa State University and has a population of around 60,000. 

The 79 variables focus on the quality and quantity of many physical attributes of the properties, and most of the variables are exactly the type of information that a typical home buyer wants to know about a potential property. There are variables about various area dimensions (such as lot size and different square footage variables), discrete variables that describe the number of items (e.g. bathrooms) occurring within the house, and categorical variables classifying e.g. streets and neighborhoods. 

With the dataset and based on the listed variables, we aim to predict sale prices of different Ames, Iowa properties using different machine learning models. For our predictions, we plan to use ANN, kNN, SVR, and Random Forest models, as well as a prediction model that combines all these four models. 

Besides submitting this file as our Project 3 deliverable, we will make our final predictions on a special testing dataset provided in Kaggle and use those predictions to participate in a Kaggle Competition that is based on the Ames Housing Dataset.



# 2. General Data Exploration


## Importing Train Data

```{r}
rawHouseData_Train <- read.csv("train.csv", stringsAsFactors = FALSE)
```


## Exploring Data

```{r}
str(rawHouseData_Train)
summary(rawHouseData_Train)
```



# 3. Data Cleaning


## Converting Data into Characters for Data Cleaning

```{r}
# We need to use characters for our Boruta Screening of features
CharCategory <- c(names(Filter(is.character, rawHouseData_Train)), "MSSubClass")
```


## Identifying NAs with mice

```{r}
# Importing the required libraries
library(VIM)
library(mice)

# Identifying the percentage of NAs in each column
mice_plot <- aggr(rawHouseData_Train, col=c('navyblue','yellow'),
                    numbers=TRUE, sortVars=TRUE,
                    labels=names(rawHouseData_Train), cex.axis=.4,
                    gap=3, ylab=c("Missing data","Pattern"))
```


## Removing and Imputing NAs

```{r}
# Dropping the row with NA in Electrical column (only one missing observation for the variable)
rawHouseData_Train <- rawHouseData_Train[!is.na(rawHouseData_Train$Electrical),] 

# Dropping the GarageYrBlt column - imputing NAs with year = 0 might affect regression and other garage variables exist
rawHouseData_Train <- rawHouseData_Train[,!names(rawHouseData_Train)=="GarageYrBlt"] 

# Imputing NAs in MasVnrArea with 0
rawHouseData_Train$MasVnrArea <- ifelse(is.na(rawHouseData_Train$MasVnrArea) == TRUE, 0, rawHouseData_Train$MasVnrArea)

# Imputing NAs by "Missing" for characters for the rest of the columns (i.e. e.g. PoolQC, MiscFeature, Alley), where NA means that attribute does not exist
for(i in CharCategory){
  rawHouseData_Train[,i] = ifelse(is.na(rawHouseData_Train[,i]), "Missing", rawHouseData_Train[,i])
}

# Imputing the NAs for Lot Frontage using predictive mean matching 
rawHouseData_Train <- mice(rawHouseData_Train, m=5, maxit = 50, method = 'pmm', seed = 100)
rawHouseData_Train <- mice::complete(rawHouseData_Train)
```


## Further Cleaning with Boruta Training

```{r}
# Boruta Train package to identify important features (https://www.datacamp.com/community/tutorials/feature-selection-R-boruta)

# Importing the required library
library(Boruta)

# Executing Boruta Training
set.seed(233)
boruta_Train <- Boruta(rawHouseData_Train[names(rawHouseData_Train) != "Id" & names(rawHouseData_Train) != "SalePrice" ], rawHouseData_Train$SalePrice ,  doTrace = 2)
final.boruta <- TentativeRoughFix(boruta_Train)
print(final.boruta)
plot(final.boruta)

# Selecting only the features that passed the Boruta Screening
cleanHouseData_Train <- rawHouseData_Train[getSelectedAttributes(final.boruta, withTentative = F)]

# Converting characters back into factors
cleanHouseData_Train[sapply(cleanHouseData_Train,is.character)] <- lapply(cleanHouseData_Train[sapply(cleanHouseData_Train,is.character)], as.factor)

# Adding SalePrice back into the train data
cleanHouseData_Train$SalePrice <- rawHouseData_Train$SalePrice
```


## A Look into the cleaned data

```{r}
str(cleanHouseData_Train)
summary(cleanHouseData_Train)
```



# 4. Linear and Stepwise Regressions

In this section, we conduct Linear and Stepwise Regressions to explore variable signifigance.


## Building a Linear Regression

```{r}
SalePrice_LinReg = lm(SalePrice ~ ., data = cleanHouseData_Train)
```

### Summary of Linear Regression Performance

```{r}
summary(SalePrice_LinReg)
```


## Building a Stepwise Regression

```{r}
# Importing the required library
library(MASS)

# Creating the regression
SalePrice_StepReg = stepAIC(SalePrice_LinReg, direction = "both", trace = FALSE)

```

### Summary of the Stepwise Regression Performance

```{r}
summary(SalePrice_StepReg)
```



# 5. Creating a Normalized Version of the Data


## Converting Categorical Data to Numeric Data

```{r}
cleanHouseData_Train[] <- data.matrix(cleanHouseData_Train)
```


## Normalization function

```{r}
normalize <- function(x) { 
  return((x - min(x)) / (max(x) - min(x)))
}
```


## Executing the normalization

```{r}
# Normalizing Data (excluding SalePrice column)
Norm_HouseData <- as.data.frame(lapply(cleanHouseData_Train[,!names(cleanHouseData_Train) == "SalePrice"], normalize))

# Adding the SalePrice variable to the normalized data
Norm_HouseData$SalePrice <- cleanHouseData_Train$SalePrice
```


## A look into the Normalized Data

```{r}
str(Norm_HouseData)
summary(Norm_HouseData)
```



# 6. Dividing Data into Train and Test parts


## Randomizing Data and Creating Train and Test IDs

```{r}
set.seed(300)
trainID <- sample(1:nrow(cleanHouseData_Train),0.8*nrow(cleanHouseData_Train))
testID <- setdiff(1:nrow(cleanHouseData_Train), trainID)
```


## Dividing the Original Cleaned Data into Train and Test parts

Here we divide the original cleaned data (i.e. cleanHouseData_Train) to Train and Test parts to be used in our Random Forest and SVR Models.

```{r}
OG_HouseData_Train <- cleanHouseData_Train[trainID,]
OG_HouseData_Test <- cleanHouseData_Train[testID,]
```


## Dividing the Normalized Data into Train and Test parts

Here we divide the normalized data into Train and Test parts to be used in our ANN and kNN Models.

```{r}
Norm_HouseData_Train <- Norm_HouseData[trainID,]
Norm_HouseData_Test <- Norm_HouseData[testID,]
```



# 7. Individual Predictive Models


## Random Forest Model

### Importing the required libraries

```{r}
library(caret)
library(randomForest)
```


### Renaming Train and Test Data for Clarity

```{r}
RF_HouseData_Train <- OG_HouseData_Train
RF_HouseData_Test <- OG_HouseData_Test
```

### Creating the Random Forest Model

To decide the variable combination to use in the Random Forest Model, we tested 2 different variable combinations. The first combination of variables included all variables in RF_HouseData_Train, which includes all the variables deemed as important by Boruta. The second combination of variables included all the significant variables with a p-value lower than 0.05 from the final Stepwise Regression. We used the significant variables from the final Stepwise Regression model instead of the significant variables from our first Linear Regression model because the Stepwise Regression model was more optimimized with a lower AIC.

Using only the significant variables from the Stepwise Regression produced the better accuracy out of the two options (measured by the strength of correlation between the predicted house prices and the actual house prices listed in the test part of the data) and, thus that combination of variables is chosen for our Random Forest Model. 

```{r}
set.seed(300)
RF_Model <- randomForest(SalePrice ~ MSZoning + LotFrontage + LotArea + LotShape + 
    LandContour + LandSlope + Neighborhood + Condition1 + BldgType + 
    HouseStyle + OverallQual + OverallCond + YearBuilt + Exterior1st + 
    MasVnrArea + ExterQual + BsmtQual + BsmtFinType1 + X2ndFlrSF + 
    GrLivArea + BsmtFullBath + FullBath + BedroomAbvGr + KitchenAbvGr + 
    KitchenQual + TotRmsAbvGrd + Functional + Fireplaces + GarageCars + 
    GarageQual + GarageCond + WoodDeckSF + SaleCondition, data = RF_HouseData_Train)

# Basic information about the model
RF_Model

# Plotting the Random Forest Model
plot(RF_Model)
```

### Random Forest Prediction and Results

```{r}
RF_Prediction <- predict(RF_Model, RF_HouseData_Test, type = "response")
cor(RF_Prediction,RF_HouseData_Test$SalePrice)
RMSE(RF_Prediction,RF_HouseData_Test$SalePrice)
```

There is a strong correlation of `r round(cor(RF_Prediction,RF_HouseData_Test$SalePrice), digits = 3)` between the house prices predicted by the Random Forest Model and actual prices. This implies a good prediction and that the predicted prices follow a similar trend with the real prices. Compared to the correlation achieved when when all the variables from the Boruta screening were used, the achieved correlation with this set of variables is higher by approximately 0.0006. The RMSE which is related to the predicted sum of error is `r round(RMSE(RF_Prediction,RF_HouseData_Test$SalePrice), digits = 3)`.


## ANN Model

### Importing the required libraries

```{r}
library(nnet)
require(RCurl)
```

### Renaming Train and Test Data for Clarity

```{r}
ANN_HouseData_Train <- Norm_HouseData_Train
ANN_HouseData_Test <- Norm_HouseData_Test
```

### Creating the ANN Model

In creating the ANN Model, we experimented with the same 2 variable combinations as described above for the Random Forest Model. Again, the best accuracy was achieved using only the significant variables from the Stepwise Regression. Thus, our final ANN Model uses that combination of variables.

```{r}
set.seed(300)
ANN_Model <- nnet(SalePrice ~ Neighborhood + HouseStyle + MasVnrArea + FullBath + MSZoning + Exterior1st + BsmtFinType1 + X2ndFlrSF + BedroomAbvGr + TotRmsAbvGrd + Functional + LotFrontage + LandContour + LandSlope + Condition1 + YearBuilt + ExterQual + KitchenAbvGr + KitchenQual + Fireplaces + WoodDeckSF + SaleCondition + LotArea + LotShape + BldgType + OverallQual + OverallCond + BsmtQual + GrLivArea + BsmtFullBath + KitchenQual + + GarageCars + GarageQual + GarageCond,
    data=ANN_HouseData_Train,
    size=10, linout=TRUE, skip=TRUE, MaxNWts=10000, trace=FALSE, maxit=100)

```

### ANN Prediction and Results

```{r}
# ANN Prediction
ANN_Prediction <- predict(ANN_Model, newdata=ANN_HouseData_Test[,!names(ANN_HouseData_Test)=="SalePrice"])

# ANN Results
cor(ANN_Prediction, ANN_HouseData_Test$SalePrice)
RMSE(ANN_Prediction, ANN_HouseData_Test$SalePrice)
```

The ANN Model predictions and the actual house prices have a correlation of `r round(cor(ANN_Prediction, ANN_HouseData_Test$SalePrice), digits = 3)`. This correlation is approximately 0.037 higher than the correlation obtained when all the variables from Boruta Screening were used. The RMSE is `r round(RMSE(ANN_Prediction, ANN_HouseData_Test$SalePrice), digits = 3)`. The RMSE here is higher than what we got from the Random Forest Model.


## SVR Model

### Importing the required library

```{r}
library(kernlab)
```

### Renaming Train and Test Data for Clarity

```{r}
SVR_HouseData_Train <- OG_HouseData_Train
SVR_HouseData_Test <- OG_HouseData_Test
```

### Creating the SVR Model

To decide the final form of our Support Vector Regression Model, we went through a two-step experimentation process. First we used all the variables that passed the Boruta Screening and tested how the SVR Model performs with different kernels to find the optimal kernel for the model. The tested kernels were rbfdot, vanilladot, tanhdot and polydot. The highest correlation between predicted and actual house prices was achieved using the rbfdot kernel.

In the second step, we tested if it improves the accuracy to use only the significant variables from the Stepwise Regression with the rbfdot kernel and found out that it does not - the better accuracy is achieved by using all the variables that passed the Boruta Screening. The achieved correlation between the predicted and actual house prices was approximately 0.003 better for the model that uses all the variables that passed the Boruta Screening and, thus that combination of variables is used in our final SVR Model.

```{r}
# Constructing an SVR Model with all variables that passed the Boruta Screening
set.seed(300)
SVR_Model <- ksvm(SalePrice ~ ., data = SVR_HouseData_Train,
                          kernel = "rbfdot")
```

### SVR Model Prediction and Results

```{r}
# SVR Model Prediction
SVR_Prediction <- predict(SVR_Model, SVR_HouseData_Test)

# SVR Model Results
cor(SVR_Prediction, SVR_HouseData_Test$SalePrice)
RMSE(SVR_Prediction, SVR_HouseData_Test$SalePrice)
```

The house prices predicted by the SVR Model that uses all the variables that passed the Boruta Screening and the rbfdot kernel, and the actual house prices have a correlation of `r round(cor(SVR_Prediction, SVR_HouseData_Test$SalePrice), digits = 3)`. The RMSE is `r round(RMSE(SVR_Prediction, SVR_HouseData_Test$SalePrice), digits = 3)`. This is so far the model yielding the lowest error (RMSE) in our analysis.


## kNN Model

### Renaming Train and Test Data for Clarity

```{r}
kNN_HouseData_Train <- Norm_HouseData_Train
kNN_HouseData_Test <- Norm_HouseData_Test
```

### Creating the kNN Model

For the kNN Model, we once again tested the same 2 variable combinations. Using all the variables that passed the Boruta Training seemed to produce the better accuracy and, thus that variable combination is chosen for our final kNN Model. When all the variables that passed the Boruta Training were used, the achieved correlation between the predicted and actual house prices was approximately 0.0037 higher than when only the significant variables from the Stepwise Regression were used.

```{r}
# Training Control using a repeated 10-fold cross-validation to find the optimal k-value
trControl <- trainControl(method = 'repeatedcv',number = 10, repeats = 3)
```

```{r}
# Creating the model
set.seed(300)
kNN_Model <- train(SalePrice ~ ., data = kNN_HouseData_Train, tuneGrid = expand.grid(k=1:70), method = 'knn', trControl = trControl, preProc = c('center', 'scale'))

# Plotting the kNN model
plot(kNN_Model)

# Looking into the variable importance within the kNN Model
varImp(kNN_Model)
```

The varImp function helps us see that OverallQual, GrLivArea, and TotalBsmtSF are some of the most meaningful variables in predicting the sale price of a house. Meanwhile, variables like the number of fireplaces, or the year the garage was built are not as significant in this prediction. 

### kNN Model Prediction and Results

```{r}
kNN_Prediction <- predict(kNN_Model, newdata = kNN_HouseData_Test)
plot(kNN_Prediction ~ kNN_HouseData_Test$SalePrice)
cor(kNN_Prediction, kNN_HouseData_Test$SalePrice)
RMSE(kNN_Prediction, kNN_HouseData_Test$SalePrice)
```

The plot above shows the actual sale price of a house against the predicted sale price of the house. Since the plot is pretty linear - with the exception of a few outliers - and has a slope close to one, the kNN Model seems to be a quite decent model in predicting the sale price of a house. 

The kNN Model predictions and the actual house prices have a correlation of `r round(cor(kNN_Prediction, kNN_HouseData_Test$SalePrice), digits = 3)`, which supports the indication of the plot that the kNN Model is a decent predictor for house prices. The RMSE is `r RMSE(kNN_Prediction, kNN_HouseData_Test$SalePrice)`. 



# 8. Combined Prediction Model


## Building a dataframe containing predictions of all models

```{r}
House_Prices <- data.frame(RF_Prediction,ANN_Prediction,SVR_Prediction,kNN_Prediction,OG_HouseData_Test$SalePrice)
colnames(House_Prices) <- c("Random Forest", "ANN", "SVR", "kNN", "True Price")
```


## Combined Model Prediction Models

We have built two combined models, one of which is weighted by correlation and another which is weighted by RMSE. The second combined model uses RMSEs of the individual models to conduct an inverse weighting scheme that yields the results, since a smaller RMSE means a better fit. 

### Creating the Correlation-weighted Combined Model

```{r}
# Correlations
RF_Cor <- cor(House_Prices$`Random Forest`,House_Prices$`True Price`)
ANN_Cor <- cor(House_Prices$ANN,House_Prices$`True Price`)
SVR_Cor <- cor(House_Prices$SVR,House_Prices$`True Price`)
kNN_Cor <- cor(House_Prices$kNN,House_Prices$`True Price`)

# Sum of Correlations
SUM_Of_Cor <- RF_Cor + ANN_Cor + SVR_Cor + kNN_Cor

# Weights of models
RF_WeightCor <- RF_Cor / SUM_Of_Cor
ANN_WeightCor <- ANN_Cor / SUM_Of_Cor
SVR_WeightCor <- SVR_Cor / SUM_Of_Cor
kNN_WeightCor <- kNN_Cor / SUM_Of_Cor

# Taking the correlation-weighted average of predictions
House_Prices[,"Correlation Weighted Average"] <- House_Prices$`Random Forest` * RF_WeightCor + House_Prices$ANN * ANN_WeightCor + House_Prices$SVR * SVR_WeightCor + House_Prices$kNN * kNN_WeightCor
```

### Creating the RMSE-weighted Combined Model

```{r}
# RMSE for each model
RF_RMSE <- RMSE(House_Prices$`Random Forest`,House_Prices$`True Price`)
ANN_RMSE <- RMSE(House_Prices$ANN,House_Prices$`True Price`)
SVR_RMSE <- RMSE(House_Prices$SVR,House_Prices$`True Price`)
kNN_RMSE <- RMSE(House_Prices$kNN,House_Prices$`True Price`)

# Sum of RMSEs
SUM_Of_RMSE <- RF_RMSE + ANN_RMSE + SVR_RMSE + kNN_RMSE

# Weights of models
RF_WeightRMSE <- (1 - RF_RMSE / SUM_Of_RMSE)*(1/(4-1))
ANN_WeightRMSE <- (1 - ANN_RMSE / SUM_Of_RMSE)*(1/(4-1))
SVR_WeightRMSE <- (1 - SVR_RMSE / SUM_Of_RMSE)*(1/(4-1))
kNN_WeightRMSE <- (1 - kNN_RMSE / SUM_Of_RMSE)*(1/(4-1))

# Taking the RMSE-weighted average of predictions
House_Prices[,"RMSE Weighted Average"] = House_Prices$`Random Forest` * RF_WeightRMSE + House_Prices$ANN * ANN_WeightRMSE + House_Prices$SVR * SVR_WeightRMSE + House_Prices$kNN * kNN_WeightRMSE
```


## Combined Model Results

### Results of the Correlation-weighted Model

```{r}
correlationCombined_1 <- cor(House_Prices$`Correlation Weighted Average`, House_Prices$`True Price`)
rmseCombined_1 <- RMSE(House_Prices$`Correlation Weighted Average`,House_Prices$`True Price`)
```

The house prices predicted by our correlation-weighted combined model and the actual house prices have a correlation of `r round(correlationCombined_1, digits = 3)`. The RMSE for this model is  `r round(rmseCombined_1, digits = 3)`. 

### Results of the RMSE-weighted Model

```{r}
correlationCombined_2 <- cor(House_Prices$`RMSE Weighted Average`, House_Prices$`True Price`)
rmseCombined_2 <- RMSE(House_Prices$`RMSE Weighted Average`,House_Prices$`True Price`)
```

The house prices predicted by our combined model that uses the inverse RMSE weighting and the actual house prices have a correlation of `r round(correlationCombined_2, digits = 3)`. The RMSE for the model is  `r round(rmseCombined_2, digits = 3)`.

Our combined models beat all our other models except for the SVR model in terms of correlation strength and RMSE. For our SVR model, the correlation between predicted and actual prices was `r round(cor(SVR_Prediction, SVR_HouseData_Test$SalePrice), digits = 3)` and the RMSE was `r round(RMSE(SVR_Prediction, SVR_HouseData_Test$SalePrice), digits = 3)`.



# 9. Conclusion

Our objective was to predict Ames, Iowa property prices using machine learning models. As a base for our work we used an incredible Ames Housing Dataset.

Before creating our models, we did some data cleaning. Firstly, we handled all NAs in the dataset accordingly and used the Boruta Package to identify important variables in the dataset. Furthermore, we used linear and stepwise regressions to take a basic look on the significant variables effecting house prices. 
  
Based on the cleaned data, we then went on and built four different predictive models, including a Random Forest Model, an Artificial Neural Network Model, a Support Vector Machine Model, and a k-Nearest-Neighbors Model. Out of the predictions of the four models, the predicted prices produced with the SVR Model had the highest correlation with the actual house prices listed in our Test Dataset. The correlation between the SVR Model Predictions and the actual house prices was `r round(SVR_Cor, digits = 4)`. Furthermore, the SVR also had the lowest RMSE among all models, `r round(SVR_RMSE, digits = 4)`.

The other models also performed fairly well. The Random Forest Model was the second most accurate. The correlation between the predictions made with the Random Forest Model and the actual house prices was `r round(RF_Cor, digits = 4)` Furthermore, the correlations between the predictions made by the ANN Model and the kNN Model and the actual house prices were `r round(ANN_Cor, digits = 4)` and `r round(kNN_Cor, digits = 4)` respectively.
  
After creating the four individual models, we still thought that we could improve our predictions by obtaining a correlation-weighted average and also a RMSE inverse-weighted-average of the predictions of the individual models to create combined prediction models that would then be trained across multiple mechanisms. The correlations between the price predictions made with our correlation- and RMSE-weighted combined models and the actual house prices were `r round(correlationCombined_1, digits = 3)` and `r round(correlationCombined_2, digits = 3)` respectively, along with the RMSEs being `r round(rmseCombined_1, digits = 3)` and `r round(rmseCombined_2, digits = 3)`. These results still couldn't outperform the individual SVR model in terms of neither prediction trends (correlation) nor errors (RMSE).

Finally, we use our best model, the SVR Model,  to predict the prices for Ames, Iowa houses listed in a specific testing dataset provided in Kaggle (test.csv / rawHouseData_Test) and to create a submission file including the predictions. We will submit that file to the Kaggle Competition that is based on the Ames Housing Dataset.


## Constructing the Final Prediction for the Kaggle Competition

### Importing Test Data

```{r}
rawHouseData_Test <- read.csv("test.csv", stringsAsFactors = FALSE)
```

### Cleaning the Test Data

We have to clean the Test Data in a similar fashion than what we did with the Train Data in the beginning of the file.

#### Converting Data into Characters for Data Cleaning

```{r}
CharCategory <- c(names(Filter(is.character, rawHouseData_Test)), "MSSubClass")
```

#### Removing and Imputing NAs

```{r}
# Dropping the GarageYrBlt column - imputing NAs with year = 0 might affect regression and other garage variables exist
rawHouseData_Test <- rawHouseData_Test[,!names(rawHouseData_Test)=="GarageYrBlt"]

# Imputing NAs in MasVnrArea with 0
rawHouseData_Test$MasVnrArea <- ifelse(is.na(rawHouseData_Test$MasVnrArea) == TRUE, 0, rawHouseData_Test$MasVnrArea)

# Imputing NAs by "Missing" for characters for the rest of the columns (i.e. e.g. PoolQC, MiscFeature, Alley), where NA means that attribute does not exist
for(i in CharCategory){
  rawHouseData_Test[,i] = ifelse(is.na(rawHouseData_Test[,i]), "Missing", rawHouseData_Test[,i])
}

# Imputing the NAs for Lot Frontage using predictive mean matching
rawHouseData_Test <- mice(rawHouseData_Test, m=5, maxit = 50, method = 'pmm', seed = 100)
rawHouseData_Test <- mice::complete(rawHouseData_Test)
```

#### Further Cleaning based on Boruta Training

```{r}
# Selecting only the features that passed the Boruta Screening for the Train Data
cleanHouseData_Test <- rawHouseData_Test[getSelectedAttributes(final.boruta, withTentative = F)]

# Converting characters back into factors
cleanHouseData_Test[sapply(cleanHouseData_Test,is.character)] <- lapply(cleanHouseData_Test[sapply(cleanHouseData_Test,is.character)], as.factor)

# Adding SalePrice back into the test data
cleanHouseData_Test$SalePrice <- rawHouseData_Test$SalePrice
```

#### Creating the Same Format for the Test Data that the Train Data has

```{r}
cleanHouseData_Test[] <- data.matrix(cleanHouseData_Test)
```

### Constructing the Final Prediction

```{r}
Final_Kaggle_Prediction <- predict(SVR_Model, cleanHouseData_Test)
```

### Creating the Submission File

```{r}
# Adding the necessary information
Kaggle_Submission <- as.data.frame(rawHouseData_Test$Id)
Kaggle_Submission$SalePrice <- Final_Kaggle_Prediction

# Naming the Columns for the Submission File
colnames(Kaggle_Submission) <- c("Id","SalePrice")

# Writing the Submission File
write.csv(Kaggle_Submission, file = "Ames_House_Prices.csv", row.names = FALSE)
```




